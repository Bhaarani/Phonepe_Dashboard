{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bogCfLmvkElB",
        "outputId": "1fe38c4f-d1f1-4c79-ad6f-862c5e20a9c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pulse'...\n",
            "remote: Enumerating objects: 7975, done.\u001b[K\n",
            "remote: Counting objects: 100% (7975/7975), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6637/6637), done.\u001b[K\n",
            "remote: Total 7975 (delta 2465), reused 6527 (delta 1031), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (7975/7975), 2.11 MiB | 8.47 MiB/s, done.\n",
            "Resolving deltas: 100% (2465/2465), done.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3IgGTPNkV5j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\n",
        "                       .format(user=\"root\",\n",
        "                               pw=\"\",\n",
        "                               db=\"phonepe_pluse\"))\n",
        "\n",
        "\n",
        "path = (glob.glob(r\"C:\\Users\\admin\\Desktop\\phonepe Project\\pulse\\data\\\\\\country\\india\\\\.json\", recursive=True))\n",
        "\n",
        "agger_trans_yearwise = pd.DataFrame()\n",
        "agger_user_yearwise = pd.DataFrame()\n",
        "\n",
        "map_trans_yearwise = pd.DataFrame()\n",
        "map_user_yearwise = pd.DataFrame()\n",
        "\n",
        "top_trans_yearwise = pd.DataFrame()\n",
        "top_user_yearwise = pd.DataFrame()\n",
        "\n",
        "\n",
        "splt_lst = []\n",
        "for i in path:\n",
        "    splt_lst = i.split('\\\\')\n",
        "    if splt_lst[7] ==\"aggregated\":\n",
        "\n",
        "        if splt_lst[8] == \"transaction\":\n",
        "\n",
        "            DF = pd.read_json(i)\n",
        "            j = DF.loc[\"transactionData\", \"data\"]\n",
        "            j = pd.json_normalize(j, record_path=['paymentInstruments'], meta=[\"name\"])\n",
        "\n",
        "            j[\"Year\"] = splt_lst[11]\n",
        "\n",
        "            x = splt_lst[12].split(\".\")\n",
        "            j[\"Quater\"] = x[0]\n",
        "\n",
        "            agger_trans_yearwise = pd.concat([agger_trans_yearwise, j],ignore_index=True)\n",
        "            agger_trans_yearwise.to_sql(\"agger_trans_yearwise\", con=engine, if_exists='append')\n",
        "\n",
        "        if splt_lst[8] == \"user\":\n",
        "\n",
        "            DF = pd.read_json(i)\n",
        "\n",
        "            b = DF.loc[\"usersByDevice\", \"data\"]\n",
        "            if b == None:\n",
        "                continue\n",
        "            b = pd.json_normalize(b)\n",
        "\n",
        "            c = DF.loc[\"aggregated\", \"data\"]\n",
        "            if c == None:\n",
        "                continue\n",
        "            c = pd.json_normalize(c)\n",
        "\n",
        "            b[\"Year\"] = c[\"Year\"] = splt_lst[11]\n",
        "\n",
        "            x = splt_lst[12].split(\".\")\n",
        "            b[\"Quater\"] = c[\"Quater\"] = x[0]\n",
        "\n",
        "            output = pd.concat([b, c])\n",
        "            agger_user_yearwise = pd.concat([agger_user_yearwise, output],ignore_index=True)\n",
        "            agger_user_yearwise.to_sql(\"agger_user_yearwise\", con=engine, if_exists='append')\n",
        "\n",
        "\n",
        "\n",
        "    if splt_lst[7] == \"map\":\n",
        "\n",
        "        if splt_lst[8] == \"transaction\":\n",
        "\n",
        "            DF = pd.read_json(i)\n",
        "\n",
        "            a = DF.loc[\"hoverDataList\", \"data\"]\n",
        "            a = pd.json_normalize(a, record_path=[\"metric\"], meta=[\"name\"])\n",
        "            a.columns = [\"Type\", \"Count\", \"Amount\", \"City\"]\n",
        "\n",
        "            a[\"Year\"] = splt_lst[11]\n",
        "\n",
        "            x = splt_lst[12].split(\".\")\n",
        "            a[\"Quater\"] = x[0]\n",
        "\n",
        "            map_trans_yearwise = pd.concat([map_trans_yearwise, a])\n",
        "            map_trans_yearwise.to_sql(\"map_trans_yearwise\", con=engine, if_exists='append')\n",
        "\n",
        "\n",
        "        if splt_lst[8] == \"user\":\n",
        "\n",
        "            DF = pd.read_json(i)\n",
        "\n",
        "            a = DF.loc[\"hoverData\", \"data\"]\n",
        "            a = pd.DataFrame(a)\n",
        "            a = a.transpose()\n",
        "            a.reset_index(inplace=True)\n",
        "            a.columns = [\"City\", \"RegUser\", \"AppOpens\"]\n",
        "\n",
        "            a[\"Year\"] = splt_lst[11]\n",
        "\n",
        "            x = splt_lst[12].split(\".\")\n",
        "            a[\"Quater\"] = x[0]\n",
        "\n",
        "            map_user_yearwise = pd.concat([map_user_yearwise , a])\n",
        "            map_user_yearwise.to_sql(\"map_user_yearwise\", con=engine, if_exists='append')\n",
        "\n",
        "    if splt_lst[7] == \"top\":\n",
        "\n",
        "        if splt_lst[8] == \"transaction\":\n",
        "\n",
        "            DF = pd.read_json(i)\n",
        "\n",
        "            a = DF.loc[\"districts\", \"data\"]\n",
        "            a = pd.json_normalize(a)\n",
        "            a.columns = [\"Districts\", \"Total\", \"Count\", \"Amount\"]\n",
        "\n",
        "            b = DF.loc[\"pincodes\", \"data\"]\n",
        "            b = pd.json_normalize(b)\n",
        "            b.columns = [\"Pincode\", \"Total\", \"Count\", \"Amount\"]\n",
        "\n",
        "            c = DF.loc[\"states\", \"data\"]\n",
        "            c = pd.json_normalize(c)\n",
        "            c.columns = [\"State\", \"Total\", \"Count\", \"Amount\"]\n",
        "\n",
        "            a[\"Year\"] = b[\"Year\"] = c[\"Year\"] = splt_lst[11]\n",
        "\n",
        "            x = splt_lst[12].split(\".\")\n",
        "            a[\"Quater\"] = b[\"Quater\"] = c[\"Quater\"] = x[0]\n",
        "\n",
        "            output = pd.concat([a, b, c])\n",
        "            top_trans_yearwise = pd.concat([top_trans_yearwise, output])\n",
        "            top_trans_yearwise.to_sql(\"top_trans_yearwise\", con=engine, if_exists='append')\n",
        "\n",
        "\n",
        "        if splt_lst[8] == \"user\":\n",
        "\n",
        "            DF = pd.read_json(i)\n",
        "\n",
        "            a = DF.loc[\"districts\", \"data\"]\n",
        "            a = pd.DataFrame(a)\n",
        "            a.columns = [\"District\", \"DistrictRegUser\"]\n",
        "\n",
        "            b = DF.loc[\"pincodes\", \"data\"]\n",
        "            b = pd.DataFrame(b)\n",
        "            b.columns = [\"Pincode\", \"PincodeRegUser\"]\n",
        "\n",
        "            c = DF.loc[\"states\", \"data\"]\n",
        "            c = pd.DataFrame(c)\n",
        "            c.columns = [\"State\", \"StateRegUser\"]\n",
        "\n",
        "            a[\"Year\"] = b[\"Year\"] = c[\"Year\"] = splt_lst[11]\n",
        "\n",
        "\n",
        "            x = splt_lst[12].split(\".\")\n",
        "            a[\"Quater\"] = b[\"Quater\"] = c[\"Quater\"] = x[0]\n",
        "\n",
        "            output = pd.concat([a, b, c])\n",
        "            top_user_yearwise = pd.concat([top_user_yearwise, output])\n",
        "\n",
        "            # Insert whole DataFrame into MySQL\n",
        "            top_user_yearwise.to_sql(\"top_user_yearwise\", con=engine, if_exists='append')\n",
        "\n",
        "\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "path_state = (glob.glob(r\"C:\\Users\\admin\\Desktop\\phonepe Project\\pulse\\data\\\\\\country\\india\\\\.json\", recursive=True))\n",
        "\n",
        "agger_trans_statewise = pd.DataFrame()\n",
        "agger_user_statewise = pd.DataFrame()\n",
        "\n",
        "map_trans_statewise = pd.DataFrame()\n",
        "map_user_statewise = pd.DataFrame()\n",
        "\n",
        "top_trans_statewise = pd.DataFrame()\n",
        "top_user_statewise = pd.DataFrame()"
      ],
      "metadata": {
        "id": "NB0gkRM3tzZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "zsuUg-cmz3Hc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}